{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project I was inspired to do was my one of Linkedin connection, who was working on a Ed-tech startup and they were building a system for childerens who have difficulty in reading the text. Which can be used when you come across images and PDFs containing important textual content you want to extract the text instead of typing manually. So I came up with this project to tackle that problem. Technology used was Optical Character Recognition(OCR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Optical Character Recognition(OCR)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggest,OCR is used for recognizing Character from image and convert them into string format. So the program analyzes the structure of document image. It divides the page into elements such as blocks of texts, tables, images, etc. The lines are divided into words and then - into characters. Once the characters have been singled out, the program compares them with a set of pattern images. It advances numerous hypotheses about what this character is. Basing on these hypotheses the program analyzes different variants of breaking of lines into words and words into characters. After processing huge number of such probabilistic hypotheses, the program finally takes the decision, presenting you the recognized text."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Technology Used: \n",
    "    PyTesseract Library:\n",
    "        It is wrapper for Google's Tesseract-OCR Engine plus it is open source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from pytesseract) (5.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ronak jain\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "import cv2 \n",
    "import pytesseract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Download the Model from the below link and save it to a folder.\n",
    "After Downloading, Load the model by giving path to the folder same goes to image(i.e img)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the installed location of Tesseract-OCR in your system \n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\RONAK JAIN\\AppData\\Local\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# Read image from which text needs to be extracted \n",
    "img = cv2.imread(\"C:/Users/RONAK JAIN/Pictures/Screenshots/images1.jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the image starts by converting the image to gray scale from RGB\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Performing OTSU threshold \n",
    "\n",
    "Otsu Thresholding Explained:\n",
    "Otsu's thresholding method involves iterating through all the possible threshold values and calculating a measure of spread for the pixel levels each side of the threshold, i.e. the pixels that either fall in foreground or background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV) \n",
    "\n",
    "# Specify structure shape and kernel size. \n",
    "# Kernel size increases or decreases the area of the rectangle to be detected. \n",
    "# A smaller value like (10, 10) will detect each word instead of a sentence. \n",
    "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18)) \n",
    "\n",
    "# Appplying dilation on the threshold image \n",
    "dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1) \n",
    "\n",
    "# Finding contours \n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "# Creating a copy of image \n",
    "im2 = img.copy() \n",
    "\n",
    "# A text file is created and flushed \n",
    "file = open(\"sample.txt\", \"w+\") \n",
    "file.write(\"\") \n",
    "file.close() \n",
    "\n",
    "# Looping through the identified contours \n",
    "# Then rectangular part is cropped and passed on \n",
    "# to pytesseract for extracting text from it \n",
    "# Extracted text is then written into the text file \n",
    "for cnt in contours: \n",
    "    x, y, w, h = cv2.boundingRect(cnt) \n",
    "\n",
    "    # Drawing a rectangle on copied image \n",
    "    rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2) \n",
    "    \n",
    "    # Cropping the text block for giving input to OCR \n",
    "    cropped = im2[y:y + h, x:x + w] \n",
    "    \n",
    "    # Open the file in append mode \n",
    "    file = open(\"sample.txt\", \"a\") \n",
    "    \n",
    "    # Apply OCR on the cropped image \n",
    "    text = pytesseract.image_to_string(cropped) \n",
    "    print(text)\n",
    "    # Appending the text into file \n",
    "    file.write(text) \n",
    "    file.write(\"\\n\") \n",
    "    \n",
    "    # Close the file \n",
    "    file.close "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add a Text-to-speech API. Each Code explaination is commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup by installing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: gtts-token>=1.1.3 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from gTTS) (1.1.3)\n",
      "Requirement already satisfied: six in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from gTTS) (1.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from gTTS) (7.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from gTTS) (4.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from gTTS) (2.21.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from beautifulsoup4->gTTS) (1.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from requests->gTTS) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from requests->gTTS) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from requests->gTTS) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (from requests->gTTS) (1.24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ronak jain\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playsound in c:\\users\\ronak jain\\anaconda3\\lib\\site-packages (1.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ronak jain\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS\n",
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required module for text \n",
    "# to speech conversion \n",
    "from gtts import gTTS \n",
    "from playsound import playsound\n",
    "import os \n",
    "mytext = text\n",
    "language = 'en'\n",
    "\n",
    "# Passing the text and language to the engine, here we have marked slow=False.\n",
    "# Which tells the module that the converted audio should have a high speed. \n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "\n",
    "'''Saving the converted audio in a mp3 file named welcome2''' \n",
    "\n",
    "myobj.save(\"welcome2.mp3\")\n",
    "playsound(\"welcome2.mp3\")\n",
    "\n",
    "# Playing the converted file \n",
    "os.system(\"mpg321 welcome.mp3\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another approach in less then 10 line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TATINTA\n",
      "\n",
      "‘A Comprehensive\n",
      "\n",
      "‘hem\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "def ocr_core(filename):\n",
    "    \"\"\"\n",
    "    This function will handle the core OCR processing of images.\n",
    "    \"\"\"\n",
    "    text = pytesseract.image_to_string(Image.open(filename))  # We'll use Pillow's Image class to open the image and pytesseract to detect the string in the image\n",
    "    return text\n",
    "\n",
    "print(ocr_core(\"C:/Users/RONAK JAIN/Pictures/Screenshots/download.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hope you find this work useful. More Tutorials will come soon.\n"
     ]
    }
   ],
   "source": [
    "print('Hope you find this work useful. More Tutorials will come soon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONAK JAIN\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
